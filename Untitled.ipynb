{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COCO dataset parse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COCO数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "大小：25 GB（压缩）\n",
    "\n",
    "记录数量： 330K图像、80个对象类别、每幅图像有5个标签、25万个关键点。\n",
    "\n",
    "分两部分发布，前部分于2014年发布，后部分于2015年.\n",
    "- 2014年版本：\n",
    "82,783 training, 40,504 validation, and 40,775 testing images，有270k的segmented people和886k的segmented object；\n",
    "- 2015年版本：\n",
    "165,482 train, 81,208 val, and 81,434 test images。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### class label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "person(人)  bicycle(自行车)  car(汽车)  motorbike(摩托车)  aeroplane(飞机)  bus(公共汽车)  train(火车)  truck(卡车)  boat(船)  \n",
    "traffic light(信号灯)  fire hydrant(消防栓)  stop sign(停车标志)  parking meter(停车计费器)  bench(长凳)  \n",
    "bird(鸟)  cat(猫)  dog(狗)  horse(马)  sheep(羊)  cow(牛)  elephant(大象)  bear(熊)  zebra(斑马)  giraffe(长颈鹿)  \n",
    "backpack(背包)  umbrella(雨伞)  handbag(手提包)  tie(领带)  suitcase(手提箱)  \n",
    "frisbee(飞盘)  skis(滑雪板双脚)  snowboard(滑雪板)  sports ball(运动球)  kite(风筝) baseball bat(棒球棒)  baseball glove(棒球手套)  skateboard(滑板)  surfboard(冲浪板)  tennis racket(网球拍)  \n",
    "bottle(瓶子)  wine glass(高脚杯)  cup(茶杯)  fork(叉子)  knife(刀)\n",
    "spoon(勺子)  bowl(碗)  \n",
    "banana(香蕉)  apple(苹果)  sandwich(三明治)  orange(橘子)  broccoli(西兰花)  carrot(胡萝卜)  hot dog(热狗)  pizza(披萨)  donut(甜甜圈)  cake(蛋糕)\n",
    "chair(椅子)  sofa(沙发)  pottedplant(盆栽植物)  bed(床)  diningtable(餐桌)  toilet(厕所)  tvmonitor(电视机)  \n",
    "laptop(笔记本)  mouse(鼠标)  remote(遥控器)  keyboard(键盘)  cell phone(电话)  \n",
    "microwave(微波炉)  oven(烤箱)  toaster(烤面包器)  sink(水槽)  refrigerator(冰箱)\n",
    "book(书)  clock(闹钟)  vase(花瓶)  scissors(剪刀)  teddy bear(泰迪熊)  hair drier(吹风机)  toothbrush(牙刷)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3种标注类型，使用json文件存储，每种类型包含了训练和验证\n",
    "- instances（目标实例）： \n",
    "也就是目标检测object detection\n",
    "- keypoints（目标上的关键点）\n",
    "- captions（看图说话）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read annocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "annotation_path = r\"H:\\deepLearning\\dataset\\COCO2014\\annotations_trainval2014\\annotations\"\n",
    "json_file = os.path.join(annotation_path, 'instances_train2014.json')\n",
    "with open(json_file) as f:\n",
    "    data = json.load(f)\n",
    "print(type(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看annotation内的具体信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info\n",
      "images\n",
      "licenses\n",
      "annotations\n",
      "categories\n"
     ]
    }
   ],
   "source": [
    "for k in data.keys():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在images中存放了照片名字信息和ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'license': 5, 'file_name': 'COCO_train2014_000000057870.jpg', 'coco_url': 'http://images.cocodataset.org/train2014/COCO_train2014_000000057870.jpg', 'height': 480, 'width': 640, 'date_captured': '2013-11-14 16:28:13', 'flickr_url': 'http://farm4.staticflickr.com/3153/2970773875_164f0c0b83_z.jpg', 'id': 57870}\n"
     ]
    }
   ],
   "source": [
    "print(data['images'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在annotation中存放了ID和bbox,特别注意\n",
    "- annotation存放的标签顺序并不是与images存放的顺序一致，而是二者通过ID进行匹配\n",
    "- annotation的每个成员只保存了某个图片的一个目标，也就是说一个图片如果有多个目标，目标信息可能分布在多个annotation成员中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'segmentation': [[312.29, 562.89, 402.25, 511.49, 400.96, 425.38, 398.39, 372.69, 388.11, 332.85, 318.71, 325.14, 295.58, 305.86, 269.88, 314.86, 258.31, 337.99, 217.19, 321.29, 182.49, 343.13, 141.37, 348.27, 132.37, 358.55, 159.36, 377.83, 116.95, 421.53, 167.07, 499.92, 232.61, 560.32, 300.72, 571.89]], 'area': 54652.9556, 'iscrowd': 0, 'image_id': 480023, 'bbox': [116.95, 305.86, 285.3, 266.03], 'category_id': 58, 'id': 86}\n"
     ]
    }
   ],
   "source": [
    "print(data['annotations'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## coco annocation to YOLO labels\n",
    "参考：https://github.com/ultralytics/JSON2YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_folders(path='../out/'):\n",
    "    # Create folders\n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path)  # delete output folder\n",
    "    os.makedirs(path)  # make new output folder\n",
    "    os.makedirs(path + os.sep + 'labels')  # make new labels folder\n",
    "    os.makedirs(path + os.sep + 'images')  # make new labels folder\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coco91_to_coco80_class():  # converts 91-index to 80-index (val2014)  (paper)\n",
    "    # https://tech.amikelive.com/node-718/what-object-categories-labels-are-in-coco-dataset/\n",
    "    # a = np.loadtxt('data/coco.names', dtype='str', delimiter='\\n')\n",
    "    # b = np.loadtxt('data/coco_paper.names', dtype='str', delimiter='\\n')\n",
    "    # x1 = [list(a[i] == b).index(True) + 1 for i in range(80)]  # darknet to coco\n",
    "    # x2 = [list(b[i] == a).index(True) if any(b[i] == a) else None for i in range(91)]  # coco to darknet\n",
    "    x = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, None, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, None, 24, 25, None,\n",
    "         None, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, None, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
    "         51, 52, 53, 54, 55, 56, 57, 58, 59, None, 60, None, None, 61, None, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
    "         None, 73, 74, 75, 76, 77, 78, 79, None]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_coco_json(path,file):\n",
    "    '''\n",
    "    path: annotations的路径\n",
    "    file: path中的某个json文件名\n",
    "    '''\n",
    "    out_dir = make_folders(path+'/out/')  # output directory\n",
    "\n",
    "    json_file = os.path.join(path, file)\n",
    "    coco80 = coco91_to_coco80_class()\n",
    "    \n",
    "    with open(json_file) as f:\n",
    "        data = json.load(f)\n",
    "        \n",
    "    # Create image dict\n",
    "    # 其内成员例如：images['57870':'COCO_train2014_000000057870.jpg']\n",
    "    images = {'%g' % x['id']: x for x in data['images']}\n",
    "    \n",
    "    # Write labels file\n",
    "    for x in tqdm(data['annotations'], desc='Annotations %s' % json_file):\n",
    "        # x['iscrowd']=1说明bbox框内的是一组对象，否则是单个对象\n",
    "        if x['iscrowd']:\n",
    "            continue\n",
    "\n",
    "        img = images['%g' % x['image_id']]\n",
    "        h, w, f = img['height'], img['width'], img['file_name']\n",
    "\n",
    "        # The Labelbox bounding box format is [top left x, top left y, width, height]\n",
    "        box = np.array(x['bbox'], dtype=np.float64)\n",
    "        box[:2] += box[2:] / 2  # xy top-left corner to center\n",
    "        box[[0, 2]] /= w  # normalize x\n",
    "        box[[1, 3]] /= h  # normalize y\n",
    "        \n",
    "        fn =  out_dir + 'labels/'\n",
    "        if (box[2] > 0.) and (box[3] > 0.):  # if w > 0 and h > 0\n",
    "            label_f = os.path.splitext(f)[0] + '.txt'\n",
    "            # 只写模式，追加写\n",
    "            with open(fn + label_f, 'a') as file:\n",
    "                file.write('%g %.6f %.6f %.6f %.6f\\n' % (coco80[x['category_id'] - 1], *box))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Annotations H:\\deepLearning\\dataset\\COCO2014\\annotations_trainval2014\\annotations\\instances_train2014.json:   2%| | 907\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-1f97fcd77dd8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mannotation_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mr\"H:\\deepLearning\\dataset\\COCO2014\\annotations_trainval2014\\annotations\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtrain_json\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'instances_train2014.json'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mconvert_coco_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mannotation_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_json\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-40-98fe8b17761a>\u001b[0m in \u001b[0;36mconvert_coco_json\u001b[1;34m(path, file)\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[0mlabel_f\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.txt'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[1;31m# 只写模式，追加写\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlabel_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'a'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m                 \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%g %.6f %.6f %.6f %.6f\\n'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcoco80\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'category_id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mbox\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dp_home\\lib\\_bootlocale.py\u001b[0m in \u001b[0;36mgetpreferredencoding\u001b[1;34m(do_setlocale)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplatform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"win\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0mgetpreferredencoding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdo_setlocale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_locale\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getdefaultlocale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "annotation_path = r\"H:\\deepLearning\\dataset\\COCO2014\\annotations_trainval2014\\annotations\"\n",
    "train_json = 'instances_train2014.json'\n",
    "convert_coco_json(annotation_path, train_json)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### val2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Annotations H:\\deepLearning\\dataset\\COCO2014\\annotations_trainval2014\\annotations\\instances_val2014.json: 100%|█| 29187\n"
     ]
    }
   ],
   "source": [
    "annotation_path = r\"H:\\deepLearning\\dataset\\COCO2014\\annotations_trainval2014\\annotations\"\n",
    "val_json = 'instances_val2014.json'\n",
    "convert_coco_json(annotation_path, val_json)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_file(path_images, txt_name):\n",
    "    '''\n",
    "    将所有数据集内的图片名写入txt文件\n",
    "    '''\n",
    "    file_imgs = os.listdir(path_images)\n",
    "    contents = \"\"\n",
    "    with open(txt_name,'w') as f:\n",
    "        contents = \"\"\n",
    "        for img in tqdm(file_imgs):\n",
    "            contents = f\"{os.path.join(path_images, img)}\\n\"\n",
    "            f.write(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 40504/40504 [00:00<00:00, 288182.84it/s]\n"
     ]
    }
   ],
   "source": [
    "path_images = r\"H:\\deepLearning\\dataset\\COCO2014\\val2014\\val2014\"\n",
    "txt_name    = r\"H:\\deepLearning\\dataset\\COCO2014\\valid.txt\"\n",
    "generate_file(path_images, txt_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 82783/82783 [00:00<00:00, 287011.76it/s]\n"
     ]
    }
   ],
   "source": [
    "path_images = r\"H:\\deepLearning\\dataset\\COCO2014\\train2014\"\n",
    "txt_name    = r\"H:\\deepLearning\\dataset\\COCO2014\\train.txt\"\n",
    "generate_file(path_images, txt_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文件名分离"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('a', 'b.jpg')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'a/b.jpg'\n",
    "os.path.split(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('b', '.jpg')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'b.jpg'\n",
    "os.path.splitext(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 字符串格式化\n",
    "- %g:浮点数字，不用加小数点\n",
    "- %f:浮点数字，有小数点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2.1', '3']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1.0,2,3]\n",
    "b = ['%g'%x  for x in a]\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.000000', '2.000000', '3.000000']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1.0,2,3]\n",
    "b = ['%f'%x  for x in a]\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
